{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcsv\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mselenium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mselenium\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwebdriver\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mselenium\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwebdriver\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchrome\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Service\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "# === CONFIG ===\n",
    "maps_url = \"https://www.google.com/maps/place/Pearl+Continental+Hotel+Rawalpindi/data=!4m10!3m9!1s0x38df9363b8ad0a09:0xb00ace25d4922b2c!5m2!4m1!1i2!8m2!3d33.588719!4d73.056722!16s%2Fg%2F12cnws5r7!19sChIJCQqtuGOT3zgRLCuS1CXOCrA?authuser=0&hl=en&rclk=1\"\n",
    "chromedriver_path = r\"E:\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "output_file = \"cheesecake_factory_reviews.csv\"\n",
    "\n",
    "# === SETUP SELENIUM WITH ANTI-DETECTION ===\n",
    "chrome_options = Options()\n",
    "# Keep browser visible for debugging - comment out headless for now\n",
    "# chrome_options.add_argument(\"--headless=new\")\n",
    "\n",
    "# Anti-detection measures\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "chrome_options.add_argument(\"--disable-web-security\")\n",
    "chrome_options.add_argument(\"--allow-running-insecure-content\")\n",
    "\n",
    "try:\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # Execute CDP commands to hide webdriver\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    print(\"üåê Opening Google Maps...\")\n",
    "    driver.get(maps_url)\n",
    "    time.sleep(8)  # Longer initial wait\n",
    "    \n",
    "    # === CLOSE COOKIE POPUP IF PRESENT ===\n",
    "    try:\n",
    "        reject_btn = driver.find_element(By.XPATH, \"//button[contains(., 'Reject all')]\")\n",
    "        reject_btn.click()\n",
    "        print(\"‚úÖ Closed cookie popup\")\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è No cookie popup detected\")\n",
    "    \n",
    "    # === OPEN ALL REVIEWS ===\n",
    "    print(\"üîç Looking for reviews button...\")\n",
    "    try:\n",
    "        # Wait and try to find reviews button\n",
    "        possible_xpaths = [\n",
    "            \"//button[contains(@aria-label,'Reviews')]\",\n",
    "            \"//button[contains(@aria-label,'reviews')]\",\n",
    "            \"//button[contains(@data-tab-index,'1')]\",\n",
    "            \"//button[.//span[contains(text(),'Reviews')]]\",\n",
    "            \"//button[.//span[contains(text(),'reviews')]]\"\n",
    "        ]\n",
    "        \n",
    "        all_reviews_btn = None\n",
    "        for xpath in possible_xpaths:\n",
    "            try:\n",
    "                all_reviews_btn = WebDriverWait(driver, 5).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "                )\n",
    "                print(f\"   Found button with xpath: {xpath[:50]}...\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if all_reviews_btn:\n",
    "            # Scroll to button first\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", all_reviews_btn)\n",
    "            time.sleep(1)\n",
    "            all_reviews_btn.click()\n",
    "            print(\"‚úÖ Clicked reviews button\")\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Could not find reviews button - reviews might already be visible\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error with reviews button: {e}\")\n",
    "        print(\"   Continuing anyway - reviews might already be visible\")\n",
    "    \n",
    "    # === FIND SCROLL CONTAINER ===\n",
    "    print(\"üìú Looking for scrollable reviews container...\")\n",
    "    scroll_div = None\n",
    "    scroll_xpaths = [\n",
    "        '//div[contains(@class,\"m6QErb\") and contains(@class,\"DxyBCb\")]',\n",
    "        '//div[@role=\"main\"]//div[contains(@class,\"m6QErb\")]',\n",
    "        '//div[contains(@aria-label,\"Reviews\")]',\n",
    "    ]\n",
    "    \n",
    "    for xpath in scroll_xpaths:\n",
    "        try:\n",
    "            scroll_div = driver.find_element(By.XPATH, xpath)\n",
    "            print(f\"   Found scroll container\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not scroll_div:\n",
    "        print(\"‚ùå Could not find scroll container. Exiting.\")\n",
    "        driver.quit()\n",
    "        exit()\n",
    "    \n",
    "    # === SCROLL AND LOAD REVIEWS ===\n",
    "    print(\"üîÅ Scrolling through reviews...\")\n",
    "    last_height = 0\n",
    "    same_count = 0\n",
    "    max_same = 5\n",
    "    scroll_attempts = 0\n",
    "    max_scrolls = 100\n",
    "    \n",
    "    while scroll_attempts < max_scrolls:\n",
    "        try:\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scroll_div)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            new_height = driver.execute_script('return arguments[0].scrollHeight', scroll_div)\n",
    "            \n",
    "            # Expand \"More\" buttons\n",
    "            try:\n",
    "                more_buttons = driver.find_elements(By.XPATH, '//button[@aria-label=\"See more\" or contains(@class,\"w8nwRe\")]')\n",
    "                for btn in more_buttons[:3]:\n",
    "                    try:\n",
    "                        if btn.is_displayed():\n",
    "                            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                            time.sleep(0.5)\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if new_height == last_height:\n",
    "                same_count += 1\n",
    "            else:\n",
    "                same_count = 0\n",
    "            \n",
    "            if same_count >= max_same:\n",
    "                print(f\"   Reached end after {scroll_attempts} scrolls\")\n",
    "                break\n",
    "            \n",
    "            last_height = new_height\n",
    "            scroll_attempts += 1\n",
    "            \n",
    "            if scroll_attempts % 10 == 0:\n",
    "                current_reviews = len(driver.find_elements(By.XPATH, '//div[@data-review-id]'))\n",
    "                print(f\"   Scrolled {scroll_attempts} times... Found {current_reviews} reviews so far\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Error during scroll: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(\"‚úÖ Scrolling complete. Extracting reviews...\")\n",
    "    \n",
    "    # === EXTRACT REVIEWS ===\n",
    "    reviews_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    print(f\"üßæ Found {len(reviews_elements)} review containers\")\n",
    "    \n",
    "    if len(reviews_elements) == 0:\n",
    "        print(\"‚ö†Ô∏è No reviews found. Saving page source for debugging...\")\n",
    "        with open(\"debug_page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)\n",
    "        print(\"   Page source saved to debug_page_source.html\")\n",
    "    \n",
    "    reviews_data = []\n",
    "    \n",
    "    for idx, r in enumerate(reviews_elements):\n",
    "        try:\n",
    "            # Extract rating\n",
    "            rating = None\n",
    "            try:\n",
    "                rating_elem = r.find_element(By.XPATH, './/*[contains(@aria-label,\"star\")]')\n",
    "                rating = rating_elem.get_attribute(\"aria-label\")\n",
    "            except:\n",
    "                try:\n",
    "                    rating_elem = r.find_element(By.XPATH, './/span[@role=\"img\"]')\n",
    "                    rating = rating_elem.get_attribute(\"aria-label\")\n",
    "                except:\n",
    "                    rating = \"No rating\"\n",
    "            \n",
    "            # Extract review text\n",
    "            text = \"\"\n",
    "            try:\n",
    "                text_elem = r.find_element(By.XPATH, './/span[@class=\"wiI7pd\"]')\n",
    "                text = text_elem.text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    text_elem = r.find_element(By.XPATH, './/div[contains(@class,\"MyEned\")]')\n",
    "                    text = text_elem.text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Debug first few reviews\n",
    "            if idx < 3:\n",
    "                print(f\"\\n--- Review {idx+1} ---\")\n",
    "                print(f\"Rating: {rating}\")\n",
    "                print(f\"Text: {text[:100] if text else '(empty)'}...\")\n",
    "            \n",
    "            if rating or text:\n",
    "                reviews_data.append([rating, text])\n",
    "                \n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            if idx < 5:\n",
    "                print(f\"   Error on review {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüìä Successfully extracted {len(reviews_data)} reviews\")\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # === SAVE CSV ===\n",
    "    if len(reviews_data) > 0:\n",
    "        with open(output_file, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Rating\", \"Review\"])\n",
    "            writer.writerows(reviews_data)\n",
    "        print(f\"‚úÖ Done! {len(reviews_data)} reviews saved to '{output_file}'\")\n",
    "    else:\n",
    "        print(\"‚ùå No reviews were extracted. Check debug_page_source.html to see what the page looks like.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Fatal error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Opening Google Maps...\n",
      "‚ÑπÔ∏è No cookie popup detected\n",
      "üîç Looking for reviews button...\n",
      "‚úÖ Clicked reviews button\n",
      "üîΩ Setting sort order to 'Newest'...\n",
      "‚ÑπÔ∏è Could not change sort order: Message: invalid session id: session deleted as the browser has closed the connection\n",
      "from disconnected: not connected to DevTools\n",
      "  (Session info: chrome=142.0.7444.177); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x7ff68cda7a35\n",
      "\t0x7ff68cda7a90\n",
      "\t0x7ff68cb216ad\n",
      "\t0x7ff68cb0d1c5\n",
      "\t0x7ff68cb32a5a\n",
      "\t0x7ff68cbaa306\n",
      "\t0x7ff68cbcb222\n",
      "\t0x7ff68cb6b068\n",
      "\t0x7ff68cb6be93\n",
      "\t0x7ff68d0629d0\n",
      "\t0x7ff68d05ce50\n",
      "\t0x7ff68d07cc45\n",
      "\t0x7ff68cdc30ce\n",
      "\t0x7ff68cdcadbf\n",
      "\t0x7ff68cdb0c14\n",
      "\t0x7ff68cdb0dcf\n",
      "\t0x7ff68cd96828\n",
      "\t0x7ffd510153e0\n",
      "\t0x7ffd529a485b\n",
      "\n",
      "üìú Looking for scrollable reviews container...\n",
      "‚ùå Could not find scroll container. Exiting.\n",
      "üîÅ Scrolling through reviews (this may take several minutes)...\n",
      "   Error during scroll: HTTPConnectionPool(host='localhost', port=59717): Max retries exceeded with url: /session/d5823b0b1dfbecffbe56987c5689b313/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001617BE4FC80>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "‚úÖ Scrolling complete after 0 scrolls\n",
      "üßæ Found 0 unique review IDs\n",
      "üìù Extracting review data...\n",
      "\n",
      "‚ùå Fatal error: HTTPConnectionPool(host='localhost', port=59717): Max retries exceeded with url: /session/d5823b0b1dfbecffbe56987c5689b313/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001617BE80740>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connection.py\", line 494, in request\n",
      "    self.endheaders()\n",
      "  File \"C:\\Users\\ABC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 1331, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\ABC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 1091, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\ABC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 1035, in send\n",
      "    self.connect()\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connection.py\", line 325, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001617BE80740>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ABC\\AppData\\Local\\Temp\\ipykernel_69644\\4019607861.py\", line 203, in <module>\n",
      "    reviews_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 967, in find_elements\n",
      "    return self.execute(Command.FIND_ELEMENTS, {\"using\": by, \"value\": value})[\"value\"] or []\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 455, in execute\n",
      "    response = cast(RemoteConnection, self.command_executor).execute(driver_command, params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\", line 407, in execute\n",
      "    return self._request(command_info[0], url, body=data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\", line 431, in _request\n",
      "    response = self._conn.request(method, url, body=body, headers=headers, timeout=self._client_config.timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\_request_methods.py\", line 143, in request\n",
      "    return self.request_encode_body(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\_request_methods.py\", line 278, in request_encode_body\n",
      "    return self.urlopen(method, url, **extra_kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\poolmanager.py\", line 459, in urlopen\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Google_map_data_scraping\\google map reviews scraping\\mapscraper\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=59717): Max retries exceeded with url: /session/d5823b0b1dfbecffbe56987c5689b313/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001617BE80740>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "# === CONFIG ===\n",
    "maps_url = \"https://www.google.com/maps/place/Semicolon+Cafe/@47.6119559,-122.200889,17z/data=!3m1!4b1!4m6!3m5!1s0x54906d666ec16e35:0x7b19a782bd3e0877!8m2!3d47.6119559!4d-122.200889!16s%2Fg%2F11rwmdyt7w?entry=ttu&g_ep=EgoyMDI1MTEwMi4wIKXMDSoASAFQAw%3D%3D\"\n",
    "chromedriver_path = r\"E:\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "output_file = \"cheesecake_factory_reviews.csv\"\n",
    "\n",
    "# === SETUP SELENIUM WITH ANTI-DETECTION ===\n",
    "chrome_options = Options()\n",
    "# Keep browser visible for debugging\n",
    "# chrome_options.add_argument(\"--headless=new\")\n",
    "\n",
    "# Anti-detection measures\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "try:\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # Execute CDP commands to hide webdriver\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    print(\"üåê Opening Google Maps...\")\n",
    "    driver.get(maps_url)\n",
    "    time.sleep(8)\n",
    "    \n",
    "    # === CLOSE COOKIE POPUP IF PRESENT ===\n",
    "    try:\n",
    "        reject_btn = driver.find_element(By.XPATH, \"//button[contains(., 'Reject all')]\")\n",
    "        reject_btn.click()\n",
    "        print(\"‚úÖ Closed cookie popup\")\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è No cookie popup detected\")\n",
    "    \n",
    "    # === OPEN ALL REVIEWS ===\n",
    "    print(\"üîç Looking for reviews button...\")\n",
    "    try:\n",
    "        possible_xpaths = [\n",
    "            \"//button[contains(@aria-label,'Reviews')]\",\n",
    "            \"//button[contains(@aria-label,'reviews')]\",\n",
    "            \"//button[contains(@data-tab-index,'1')]\",\n",
    "            \"//button[.//span[contains(text(),'Reviews')]]\",\n",
    "            \"//button[.//span[contains(text(),'reviews')]]\"\n",
    "        ]\n",
    "        \n",
    "        all_reviews_btn = None\n",
    "        for xpath in possible_xpaths:\n",
    "            try:\n",
    "                all_reviews_btn = WebDriverWait(driver, 5).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "                )\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if all_reviews_btn:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", all_reviews_btn)\n",
    "            time.sleep(1)\n",
    "            all_reviews_btn.click()\n",
    "            print(\"‚úÖ Clicked reviews button\")\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Could not find reviews button\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error with reviews button: {e}\")\n",
    "    \n",
    "    # === SORT BY NEWEST (to get consistent results) ===\n",
    "    try:\n",
    "        print(\"üîΩ Setting sort order to 'Newest'...\")\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label,'Sort') or contains(@data-value,'Sort')]\"))\n",
    "        )\n",
    "        sort_button.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click \"Newest\" option\n",
    "        newest_option = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//div[@role='menuitemradio' and contains(.,'Newest')]\"))\n",
    "        )\n",
    "        newest_option.click()\n",
    "        time.sleep(3)\n",
    "        print(\"‚úÖ Sorted by Newest\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è Could not change sort order: {e}\")\n",
    "    \n",
    "    # === FIND SCROLL CONTAINER ===\n",
    "    print(\"üìú Looking for scrollable reviews container...\")\n",
    "    scroll_div = None\n",
    "    scroll_xpaths = [\n",
    "        '//div[contains(@class,\"m6QErb\") and contains(@class,\"DxyBCb\")]',\n",
    "        '//div[@role=\"main\"]//div[contains(@class,\"m6QErb\")]',\n",
    "        '//div[contains(@aria-label,\"Reviews\")]',\n",
    "    ]\n",
    "    \n",
    "    for xpath in scroll_xpaths:\n",
    "        try:\n",
    "            scroll_div = driver.find_element(By.XPATH, xpath)\n",
    "            print(f\"   Found scroll container\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not scroll_div:\n",
    "        print(\"‚ùå Could not find scroll container. Exiting.\")\n",
    "        driver.quit()\n",
    "        exit()\n",
    "    \n",
    "    # === SCROLL AND LOAD REVIEWS WITH DEDUPLICATION ===\n",
    "    print(\"üîÅ Scrolling through reviews (this may take several minutes)...\")\n",
    "    \n",
    "    seen_review_ids = set()  # Track unique review IDs\n",
    "    last_count = 0\n",
    "    no_new_reviews_count = 0\n",
    "    max_no_new = 10  # Stop if no new reviews after 10 scrolls\n",
    "    scroll_attempts = 0\n",
    "    max_scrolls = 300  # Increase max scrolls to get all reviews\n",
    "    \n",
    "    while scroll_attempts < max_scrolls:\n",
    "        try:\n",
    "            # Scroll down\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scroll_div)\n",
    "            time.sleep(2.5)  # Wait for content to load\n",
    "            \n",
    "            # Expand \"More\" buttons to get full review text\n",
    "            try:\n",
    "                more_buttons = driver.find_elements(By.XPATH, '//button[@aria-label=\"See more\" or contains(@class,\"w8nwRe\")]')\n",
    "                for btn in more_buttons[:5]:  # Expand first 5 visible\n",
    "                    try:\n",
    "                        if btn.is_displayed():\n",
    "                            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                            time.sleep(0.3)\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Count unique reviews\n",
    "            current_reviews = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "            current_unique_ids = set()\n",
    "            for r in current_reviews:\n",
    "                try:\n",
    "                    review_id = r.get_attribute('data-review-id')\n",
    "                    if review_id:\n",
    "                        current_unique_ids.add(review_id)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            current_count = len(current_unique_ids)\n",
    "            \n",
    "            # Check if we found new reviews\n",
    "            if current_count == last_count:\n",
    "                no_new_reviews_count += 1\n",
    "            else:\n",
    "                no_new_reviews_count = 0\n",
    "                seen_review_ids.update(current_unique_ids)\n",
    "            \n",
    "            # Stop if no new reviews for a while\n",
    "            if no_new_reviews_count >= max_no_new:\n",
    "                print(f\"   No new reviews found after {no_new_reviews_count} scrolls. Stopping.\")\n",
    "                break\n",
    "            \n",
    "            last_count = current_count\n",
    "            scroll_attempts += 1\n",
    "            \n",
    "            # Progress update every 20 scrolls\n",
    "            if scroll_attempts % 20 == 0:\n",
    "                print(f\"   Scrolled {scroll_attempts} times... Found {current_count} unique reviews\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Error during scroll: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"‚úÖ Scrolling complete after {scroll_attempts} scrolls\")\n",
    "    print(f\"üßæ Found {len(seen_review_ids)} unique review IDs\")\n",
    "    \n",
    "    # === EXTRACT REVIEWS USING UNIQUE IDs ===\n",
    "    print(\"üìù Extracting review data...\")\n",
    "    \n",
    "    reviews_data = []\n",
    "    reviews_dict = {}  # Use dict to ensure no duplicates\n",
    "    \n",
    "    reviews_elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "    print(f\"   Processing {len(reviews_elements)} review elements...\")\n",
    "    \n",
    "    for idx, r in enumerate(reviews_elements):\n",
    "        try:\n",
    "            # Get unique review ID\n",
    "            review_id = r.get_attribute('data-review-id')\n",
    "            if not review_id or review_id in reviews_dict:\n",
    "                continue  # Skip if no ID or already processed\n",
    "            \n",
    "            # Extract rating\n",
    "            rating = None\n",
    "            try:\n",
    "                rating_elem = r.find_element(By.XPATH, './/*[contains(@aria-label,\"star\")]')\n",
    "                rating = rating_elem.get_attribute(\"aria-label\")\n",
    "            except:\n",
    "                try:\n",
    "                    rating_elem = r.find_element(By.XPATH, './/span[@role=\"img\"]')\n",
    "                    rating = rating_elem.get_attribute(\"aria-label\")\n",
    "                except:\n",
    "                    rating = \"No rating\"\n",
    "            \n",
    "            # Extract review text\n",
    "            text = \"\"\n",
    "            try:\n",
    "                text_elem = r.find_element(By.XPATH, './/span[@class=\"wiI7pd\"]')\n",
    "                text = text_elem.text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    text_elem = r.find_element(By.XPATH, './/div[contains(@class,\"MyEned\")]')\n",
    "                    text = text_elem.text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Extract reviewer name (optional, for verification)\n",
    "            reviewer = \"\"\n",
    "            try:\n",
    "                reviewer_elem = r.find_element(By.XPATH, './/div[contains(@class,\"d4r55\")]')\n",
    "                reviewer = reviewer_elem.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Extract date (optional)\n",
    "            date = \"\"\n",
    "            try:\n",
    "                date_elem = r.find_element(By.XPATH, './/span[contains(@class,\"rsqaWe\")]')\n",
    "                date = date_elem.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Store in dict using review_id as key to prevent duplicates\n",
    "            if rating or text:\n",
    "                reviews_dict[review_id] = {\n",
    "                    'rating': rating,\n",
    "                    'text': text,\n",
    "                    'reviewer': reviewer,\n",
    "                    'date': date\n",
    "                }\n",
    "            \n",
    "            # Show progress\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                print(f\"   Processed {idx + 1}/{len(reviews_elements)} elements, {len(reviews_dict)} unique reviews\")\n",
    "                \n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Convert dict to list\n",
    "    for review_id, data in reviews_dict.items():\n",
    "        reviews_data.append([data['rating'], data['text'], data['reviewer'], data['date']])\n",
    "    \n",
    "    print(f\"\\nüìä Successfully extracted {len(reviews_data)} unique reviews\")\n",
    "    \n",
    "    # Debug: Show first few reviews\n",
    "    print(\"\\n--- Sample Reviews ---\")\n",
    "    for i, review in enumerate(reviews_data[:3]):\n",
    "        print(f\"\\nReview {i+1}:\")\n",
    "        print(f\"  Rating: {review[0]}\")\n",
    "        print(f\"  Reviewer: {review[2]}\")\n",
    "        print(f\"  Date: {review[3]}\")\n",
    "        print(f\"  Text: {review[1][:100]}...\")\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # === SAVE CSV ===\n",
    "    if len(reviews_data) > 0:\n",
    "        with open(output_file, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Rating\", \"Review\", \"Reviewer\", \"Date\"])\n",
    "            writer.writerows(reviews_data)\n",
    "        print(f\"\\n‚úÖ Done! {len(reviews_data)} unique reviews saved to '{output_file}'\")\n",
    "        print(f\"üìÅ File location: {output_file}\")\n",
    "    else:\n",
    "        print(\"‚ùå No reviews were extracted.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Fatal error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Opening Google Maps...\n",
      "üîç Opening reviews...\n",
      "‚úÖ Opened reviews\n",
      "üîÅ Scrolling through reviews...\n",
      "   (This will stop automatically when all available reviews are loaded)\n",
      "   Scroll 10: 50 unique reviews (no new: 1/5)\n",
      "   Scroll 20: 120 unique reviews (no new: 0/5)\n",
      "\n",
      "‚úÖ Reached end! Found 120 unique reviews after 25 scrolls\n",
      "üìñ Expanding truncated reviews...\n",
      "   Found 109 'See more' buttons\n",
      "   Expanded 50/109...\n",
      "   Expanded 100/109...\n",
      "\n",
      "üìù Extracting review data...\n",
      "\n",
      "üìä Extracted 120 unique reviews\n",
      "\n",
      "--- First 3 Reviews ---\n",
      "\n",
      "1. Hyung Kim - 5 stars\n",
      "   Date: 15 hours ago\n",
      "   Text: ...\n",
      "\n",
      "2. Maria D - 5 stars\n",
      "   Date: 2 days ago\n",
      "   Text: Amazing place to have dinner! Has a good amount of gluten-free options, only not...\n",
      "\n",
      "3. Cole Littrell - 2 stars\n",
      "   Date: 3 days ago\n",
      "   Text: Great services. Cheesecake Serives a lot of type of food but they can‚Äôt cook any...\n",
      "\n",
      "‚úÖ SUCCESS! 120 reviews saved to 'cheesecake_factory_reviews.csv'\n",
      "\n",
      "üìä Rating Distribution:\n",
      "   5: 71 reviews\n",
      "   4: 24 reviews\n",
      "   3: 8 reviews\n",
      "   2: 8 reviews\n",
      "   1: 9 reviews\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# === CONFIG ===\n",
    "maps_url = \"https://www.google.com/maps/place/The+Cheesecake+Factory,+401+Bellevue+Square,+Bellevue,+WA+98004,+United+States\"\n",
    "chromedriver_path = r\"E:\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "output_file = \"cheesecake_factory_reviews.json\"\n",
    "\n",
    "# === SETUP SELENIUM ===\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "try:\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    print(\"üåê Opening Google Maps...\")\n",
    "    driver.get(maps_url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    # Close cookie popup if present\n",
    "    try:\n",
    "        reject_btn = driver.find_element(By.XPATH, \"//button[contains(., 'Reject all')]\")\n",
    "        reject_btn.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # === SCRAPE COMPANY NAME ===\n",
    "    print(\"üè¢ Extracting company details...\")\n",
    "    company_name = \"\"\n",
    "    phone_number = \"\"\n",
    "\n",
    "    try:\n",
    "        # Company name is usually in the h1 tag or div with fontHeadlineLarge\n",
    "        name_el = wait.until(EC.presence_of_element_located((By.XPATH, '//h1[contains(@class,\"DUwDvf\")]')))\n",
    "        company_name = name_el.text.strip()\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Could not extract company name\")\n",
    "\n",
    "    # Phone number (inside call button or info section)\n",
    "    try:\n",
    "        phone_el = driver.find_element(By.XPATH, '//button[contains(@aria-label, \"Phone\") or contains(@data-item-id, \"phone:tel\") or contains(@aria-label, \"Call\")]')\n",
    "        phone_number = phone_el.text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            phone_el = driver.find_element(By.XPATH, '//div[contains(text(), \"+\") and contains(text(), \" \")]')\n",
    "            phone_number = phone_el.text.strip()\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not extract phone number\")\n",
    "\n",
    "    print(f\"‚úÖ Company: {company_name}\")\n",
    "    print(f\"üìû Phone: {phone_number or 'Not found'}\")\n",
    "    \n",
    "    # === OPEN REVIEWS TAB ===\n",
    "    print(\"üîç Opening reviews tab...\")\n",
    "    try:\n",
    "        review_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"reviews\")]')))\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "        time.sleep(4)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not open reviews section: {e}\")\n",
    "    \n",
    "    # === FIND SCROLL CONTAINER ===\n",
    "    scroll_div = wait.until(EC.presence_of_element_located(\n",
    "        (By.XPATH, '//div[contains(@class,\"m6QErb\") and contains(@class,\"DxyBCb\")]')\n",
    "    ))\n",
    "    \n",
    "    # === SCROLL TO LOAD REVIEWS (LIMITED TO FIRST 100 FOR TEST) ===\n",
    "    print(\"üîÅ Scrolling to load reviews...\")\n",
    "    seen_ids = set()\n",
    "    scroll_count = 0\n",
    "\n",
    "    while len(seen_ids) < 100 and scroll_count < 30:\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scroll_div)\n",
    "        time.sleep(1)\n",
    "        elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "        for el in elements:\n",
    "            rid = el.get_attribute('data-review-id')\n",
    "            if rid:\n",
    "                seen_ids.add(rid)\n",
    "        scroll_count += 1\n",
    "        print(f\"   Scroll {scroll_count}: {len(seen_ids)} reviews loaded...\")\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(seen_ids)} reviews for extraction.\\n\")\n",
    "    \n",
    "    # === EXPAND \"SEE MORE\" BUTTONS ===\n",
    "    more_buttons = driver.find_elements(By.XPATH, '//button[@aria-label=\"See more\"]')\n",
    "    for btn in more_buttons:\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # === EXTRACT REVIEWS DATA ===\n",
    "    print(\"üìù Extracting reviews...\")\n",
    "    reviews_data = []\n",
    "    elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "\n",
    "    for idx, r in enumerate(elements):\n",
    "        if idx >= 100:  # Limit for testing\n",
    "            break\n",
    "        try:\n",
    "            review_id = r.get_attribute('data-review-id')\n",
    "            if not review_id:\n",
    "                continue\n",
    "\n",
    "            # Rating\n",
    "            rating = \"No rating\"\n",
    "            try:\n",
    "                rating_el = r.find_element(By.XPATH, './/*[contains(@aria-label,\"star\")]')\n",
    "                rating = rating_el.get_attribute(\"aria-label\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Text\n",
    "            text = \"\"\n",
    "            try:\n",
    "                text_el = r.find_element(By.XPATH, './/span[@class=\"wiI7pd\"]')\n",
    "                text = text_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Reviewer\n",
    "            reviewer = \"\"\n",
    "            try:\n",
    "                reviewer_el = r.find_element(By.XPATH, './/div[contains(@class,\"d4r55\")]')\n",
    "                reviewer = reviewer_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Date\n",
    "            date = \"\"\n",
    "            try:\n",
    "                date_el = r.find_element(By.XPATH, './/span[contains(@class,\"rsqaWe\")]')\n",
    "                date = date_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            reviews_data.append({\n",
    "                \"review_id\": review_id,\n",
    "                \"reviewer\": reviewer,\n",
    "                \"rating\": rating,\n",
    "                \"review_text\": text,\n",
    "                \"date\": date,\n",
    "                \"company_name\": company_name,\n",
    "                \"phone_number\": phone_number\n",
    "            })\n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    # === SAVE TO JSON ===\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(reviews_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ DONE! Extracted {len(reviews_data)} reviews saved to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Opening Google Maps...\n",
      "üè¢ Extracting company details...\n",
      "‚ö†Ô∏è Could not extract company name\n",
      "‚ö†Ô∏è Could not extract phone number\n",
      "‚úÖ Company: \n",
      "üìû Phone: Not found\n",
      "üîç Opening reviews tab...\n",
      "üîÅ Scrolling to load reviews...\n",
      "   Scroll 1: 20 reviews loaded...\n",
      "   Scroll 2: 20 reviews loaded...\n",
      "   Scroll 3: 30 reviews loaded...\n",
      "   Scroll 4: 40 reviews loaded...\n",
      "   Scroll 5: 50 reviews loaded...\n",
      "   Scroll 6: 60 reviews loaded...\n",
      "   Scroll 7: 70 reviews loaded...\n",
      "   Scroll 8: 80 reviews loaded...\n",
      "   Scroll 9: 90 reviews loaded...\n",
      "   Scroll 10: 100 reviews loaded...\n",
      "‚úÖ Loaded 100 reviews for extraction.\n",
      "\n",
      "üìù Extracting reviews...\n",
      "\n",
      "‚úÖ DONE! Extracted 100 reviews saved to cheesecake_factory_reviews.json\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# === CONFIG ===\n",
    "maps_url = \"https://www.google.com/maps/place/Semicolon+Cafe/@47.6119559,-122.200889,17z/data=!3m1!4b1!4m6!3m5!1s0x54906d666ec16e35:0x7b19a782bd3e0877!8m2!3d47.6119559!4d-122.200889!16s%2Fg%2F11rwmdyt7w?entry=ttu&g_ep=EgoyMDI1MTEwMi4wIKXMDSoASAFQAw%3D%3D\"\n",
    "chromedriver_path = r\"E:\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "output_file = \"cheesecake_factory_reviews.json\"\n",
    "\n",
    "# === SETUP SELENIUM ===\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "try:\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    print(\"üåê Opening Google Maps...\")\n",
    "    driver.get(maps_url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    # Close cookie popup if present\n",
    "    try:\n",
    "        reject_btn = driver.find_element(By.XPATH, \"//button[contains(., 'Reject all')]\")\n",
    "        reject_btn.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # === SCRAPE COMPANY NAME ===\n",
    "    print(\"üè¢ Extracting company details...\")\n",
    "    company_name = \"\"\n",
    "    phone_number = \"\"\n",
    "\n",
    "    try:\n",
    "        # Company name is usually in the h1 tag or div with fontHeadlineLarge\n",
    "        name_el = wait.until(EC.presence_of_element_located((By.XPATH, '//h1[contains(@class,\"DUwDvf\")]')))\n",
    "        company_name = name_el.text.strip()\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Could not extract company name\")\n",
    "\n",
    "    # Phone number (inside call button or info section)\n",
    "    try:\n",
    "        phone_el = driver.find_element(By.XPATH, '//button[contains(@aria-label, \"Phone\") or contains(@data-item-id, \"phone:tel\") or contains(@aria-label, \"Call\")]')\n",
    "        phone_number = phone_el.text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            phone_el = driver.find_element(By.XPATH, '//div[contains(text(), \"+\") and contains(text(), \" \")]')\n",
    "            phone_number = phone_el.text.strip()\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not extract phone number\")\n",
    "\n",
    "    print(f\"‚úÖ Company: {company_name}\")\n",
    "    print(f\"üìû Phone: {phone_number or 'Not found'}\")\n",
    "    \n",
    "    # === OPEN REVIEWS TAB ===\n",
    "    print(\"üîç Opening reviews tab...\")\n",
    "    try:\n",
    "        review_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"reviews\")]')))\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "        time.sleep(4)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not open reviews section: {e}\")\n",
    "    \n",
    "    # === FIND SCROLL CONTAINER ===\n",
    "    scroll_div = wait.until(EC.presence_of_element_located(\n",
    "        (By.XPATH, '//div[contains(@class,\"m6QErb\") and contains(@class,\"DxyBCb\")]')\n",
    "    ))\n",
    "    \n",
    "    # === SCROLL TO LOAD REVIEWS (LIMITED TO FIRST 100 FOR TEST) ===\n",
    "    print(\"üîÅ Scrolling to load reviews...\")\n",
    "    seen_ids = set()\n",
    "    scroll_count = 0\n",
    "\n",
    "    while len(seen_ids) < 100 and scroll_count < 30:\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scroll_div)\n",
    "        time.sleep(1)\n",
    "        elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "        for el in elements:\n",
    "            rid = el.get_attribute('data-review-id')\n",
    "            if rid:\n",
    "                seen_ids.add(rid)\n",
    "        scroll_count += 1\n",
    "        print(f\"   Scroll {scroll_count}: {len(seen_ids)} reviews loaded...\")\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(seen_ids)} reviews for extraction.\\n\")\n",
    "    \n",
    "    # === EXPAND \"SEE MORE\" BUTTONS ===\n",
    "    more_buttons = driver.find_elements(By.XPATH, '//button[@aria-label=\"See more\"]')\n",
    "    for btn in more_buttons:\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # === EXTRACT REVIEWS DATA ===\n",
    "    print(\"üìù Extracting reviews...\")\n",
    "    reviews_data = []\n",
    "    elements = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
    "\n",
    "    for idx, r in enumerate(elements):\n",
    "        if idx >= 100:  # Limit for testing\n",
    "            break\n",
    "        try:\n",
    "            review_id = r.get_attribute('data-review-id')\n",
    "            if not review_id:\n",
    "                continue\n",
    "\n",
    "            # Rating\n",
    "            rating = \"No rating\"\n",
    "            try:\n",
    "                rating_el = r.find_element(By.XPATH, './/*[contains(@aria-label,\"star\")]')\n",
    "                rating = rating_el.get_attribute(\"aria-label\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Text\n",
    "            text = \"\"\n",
    "            try:\n",
    "                text_el = r.find_element(By.XPATH, './/span[@class=\"wiI7pd\"]')\n",
    "                text = text_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Reviewer\n",
    "            reviewer = \"\"\n",
    "            try:\n",
    "                reviewer_el = r.find_element(By.XPATH, './/div[contains(@class,\"d4r55\")]')\n",
    "                reviewer = reviewer_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Date\n",
    "            date = \"\"\n",
    "            try:\n",
    "                date_el = r.find_element(By.XPATH, './/span[contains(@class,\"rsqaWe\")]')\n",
    "                date = date_el.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            reviews_data.append({\n",
    "                \"review_id\": review_id,\n",
    "                \"reviewer\": reviewer,\n",
    "                \"rating\": rating,\n",
    "                \"review_text\": text,\n",
    "                \"date\": date,\n",
    "                \"company_name\": company_name,\n",
    "                \"phone_number\": phone_number\n",
    "            })\n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    # === SAVE TO JSON ===\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(reviews_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ DONE! Extracted {len(reviews_data)} reviews saved to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Opening Google Maps...\n",
      "üè¢ Extracting business details...\n",
      "‚úî Company: Unknown\n",
      "‚úî Phone: \n",
      "üü¶ Opening reviews section...\n",
      "üîÅ Scrolling to load reviews...\n",
      "Scroll 1: 20 unique reviews loaded...\n",
      "‚úî Loaded 20 wrapper reviews.\n",
      "üìù Extracting review data...\n",
      "\n",
      "üéâ DONE! Extracted 20 TRUE reviews ‚Üí output\\Unknown_reviews.json\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "\n",
    "maps_url = \"https://www.google.com/maps/place/Sintra+Hotel+Islamabad/@33.7155856,73.0848467,17z/data=!3m1!4b1!4m9!3m8!1s0x38dfbf4eb4ff030b:0xc101bff92da0ee59!5m2!4m1!1i2!8m2!3d33.7155856!4d73.0848467!16s%2Fg%2F11t2lwwsdv?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MTEyMy4xIKXMDSoASAFQAw%3D%3D\"\n",
    "chromedriver_path = r\"E:\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "REVIEWS_TO_SCRAPE = 20\n",
    "\n",
    "\n",
    "# ========== SELENIUM SETUP ==========\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "\n",
    "# ========== RATING EXTRACTOR (NEW GOOGLE MAPS 2025) ==========\n",
    "\n",
    "def extract_rating_from_wrapper(wrapper):\n",
    "    \"\"\"\n",
    "    Rating is no longer inside the review block.\n",
    "    It is located inside the wrapper <div class='jftiEf'>.\n",
    "    This function handles all Google Maps DOM variations.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) aria-label rating: <span aria-label=\"5.0\">\n",
    "    try:\n",
    "        rating_el = wrapper.find_element(By.XPATH, './/span[@aria-label]')\n",
    "        aria = rating_el.get_attribute(\"aria-label\")\n",
    "        m = re.search(r\"([0-9]+(?:[.,][0-9])?)\", aria)\n",
    "        if m:\n",
    "            return m.group(1).replace(\",\", \".\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 2) alt=\"5 stars\"\n",
    "    try:\n",
    "        img = wrapper.find_element(By.XPATH, './/img[contains(@alt,\"star\")]')\n",
    "        alt = img.get_attribute(\"alt\")\n",
    "        m = re.search(r\"([0-9]+)\", alt)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3) FINAL FALLBACK ‚Äì count star icons if present\n",
    "    try:\n",
    "        stars = wrapper.find_elements(By.XPATH, './/*[contains(@class,\"kvMYJc\")]')\n",
    "        if stars:\n",
    "            return str(len(stars))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return \"No rating\"\n",
    "\n",
    "\n",
    "\n",
    "# ========== CLEAN PHONE FUNCTION ==========\n",
    "\n",
    "def clean_phone(phone):\n",
    "    if not phone:\n",
    "        return \"\"\n",
    "    phone = phone.replace(\"ÓÇ∞\", \"\").strip()\n",
    "    return re.sub(r\"[^0-9+]\", \"\", phone)\n",
    "\n",
    "\n",
    "\n",
    "# ========== MAIN EXECUTION ==========\n",
    "\n",
    "try:\n",
    "    print(\"üåç Opening Google Maps...\")\n",
    "    driver.get(maps_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Close Cookies Popup\n",
    "    try:\n",
    "        reject_btn = driver.find_element(By.XPATH, \"//button[contains(., 'Reject all')]\")\n",
    "        reject_btn.click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # ==== Extract Business Name ====\n",
    "    print(\"üè¢ Extracting business details...\")\n",
    "    try:\n",
    "        name_el = wait.until(\n",
    "            EC.visibility_of_element_located((By.XPATH, '//h1[contains(@class,\"DUwDvf\")]'))\n",
    "        )\n",
    "        company_name = name_el.text.strip()\n",
    "    except:\n",
    "        company_name = \"Unknown\"\n",
    "\n",
    "    # ==== Extract Phone Number ====\n",
    "    phone_number = \"\"\n",
    "    phone_selectors = [\n",
    "        '//button[contains(@aria-label,\"Phone\")]',\n",
    "        '//button[contains(@data-item-id,\"phone:tel\")]',\n",
    "        '//a[contains(@href,\"tel:\")]'\n",
    "    ]\n",
    "\n",
    "    for sel in phone_selectors:\n",
    "        try:\n",
    "            el = driver.find_element(By.XPATH, sel)\n",
    "            phone_number = el.text or el.get_attribute(\"href\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    phone_number = clean_phone(phone_number)\n",
    "\n",
    "    print(f\"‚úî Company: {company_name}\")\n",
    "    print(f\"‚úî Phone: {phone_number}\")\n",
    "\n",
    "    # ==== Open Reviews Tab ====\n",
    "    print(\"üü¶ Opening reviews section...\")\n",
    "    try:\n",
    "        review_tab = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"reviews\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "        time.sleep(4)\n",
    "    except Exception as e:\n",
    "        print(\"‚ö† Could not open reviews section:\", e)\n",
    "\n",
    "    # ==== Scroll to load reviews ====\n",
    "    print(\"üîÅ Scrolling to load reviews...\")\n",
    "\n",
    "    scroll_box = wait.until(\n",
    "        EC.presence_of_element_located(\n",
    "            (By.XPATH, '//div[contains(@class,\"m6QErb\") and contains(@class,\"DxyBCb\")]')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    wrappers = {}  # store wrapper divs uniquely\n",
    "    scroll_attempts = 0\n",
    "\n",
    "    while len(wrappers) < REVIEWS_TO_SCRAPE and scroll_attempts < 80:\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scroll_box)\n",
    "        time.sleep(1.2)\n",
    "\n",
    "        # Google Maps review wrapper is \"jftiEf\"\n",
    "        found = driver.find_elements(By.XPATH, '//div[contains(@class,\"jftiEf\")]')\n",
    "\n",
    "        for w in found:\n",
    "            try:\n",
    "                rid = w.find_element(By.XPATH, './/div[@data-review-id]').get_attribute(\"data-review-id\")\n",
    "                wrappers[rid] = w\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        scroll_attempts += 1\n",
    "        print(f\"Scroll {scroll_attempts}: {len(wrappers)} unique reviews loaded...\")\n",
    "\n",
    "    print(f\"‚úî Loaded {len(wrappers)} wrapper reviews.\")\n",
    "\n",
    "    # ==== Extract Reviews ====\n",
    "    print(\"üìù Extracting review data...\")\n",
    "    reviews_data = []\n",
    "\n",
    "    for rid, wrapper in list(wrappers.items())[:REVIEWS_TO_SCRAPE]:\n",
    "\n",
    "        # Rating from wrapper\n",
    "        rating = extract_rating_from_wrapper(wrapper)\n",
    "\n",
    "        # Reviewer name\n",
    "        try:\n",
    "            reviewer = wrapper.find_element(By.XPATH, './/div[contains(@class,\"d4r55\")]').text\n",
    "        except:\n",
    "            reviewer = \"\"\n",
    "\n",
    "        # Review text\n",
    "        try:\n",
    "            text = wrapper.find_element(By.XPATH, './/span[@class=\"wiI7pd\"]').text\n",
    "        except:\n",
    "            text = \"\"\n",
    "\n",
    "        # Date\n",
    "        try:\n",
    "            date = wrapper.find_element(By.XPATH, './/span[contains(@class,\"rsqaWe\")]').text\n",
    "        except:\n",
    "            date = \"\"\n",
    "\n",
    "        reviews_data.append({\n",
    "            \"review_id\": rid,\n",
    "            \"reviewer\": reviewer,\n",
    "            \"rating\": rating,\n",
    "            \"review_text\": text,\n",
    "            \"date\": date\n",
    "        })\n",
    "\n",
    "    # ==== Save Output ====\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    file_name = re.sub(r'[^A-Za-z0-9 ]+', '', company_name).replace(\" \", \"_\") + \"_reviews.json\"\n",
    "\n",
    "    path = os.path.join(\"output\", file_name)\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"company_name\": company_name,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"reviews\": reviews_data\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nüéâ DONE! Extracted {len(reviews_data)} TRUE reviews ‚Üí {path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ERROR:\", e)\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
